Training Longformer with cross-word global attention and ConvBERT on Whole Word Masking with character level hebrew input.



The trained model can be find here:
https://nlp.biu.ac.il/~elronbandel/hebrew_char_mlm/model/